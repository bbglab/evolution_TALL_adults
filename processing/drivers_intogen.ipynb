{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook process intogen results to provide a list of cancer genes with annotations of relevant involvement of the genes (biological processes, pathways, protein family ). This list is provided in supplementary materials table 3 and used in figure 1d and supplementary figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import seaborn\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare black and white lists of cancer genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_files_path = \"../ext_files/process_intogen/\"\n",
    "\n",
    "# cancer mine to check genes with very few information\n",
    "cancer_mine = pd.read_csv(os.path.join(ext_files_path,\"cancermine_collated_02102019.tsv\"), sep='\\t')\n",
    "\n",
    "# IntoGen manually curated list of genes that are most likely sequencing artifacts \n",
    "with open(os.path.join(ext_files_path, 'artifacts_intogen_24_02_2020.json')) as json_file:\n",
    "    intogen_black_list = json.load(json_file)\n",
    "    \n",
    "# Cancer Gene Census as whitelist to recover genes that are known to be drivers in other cancer types\n",
    "# that appear in Tier 3 and 4 in IntoGen\n",
    "cgc_genes = pd.read_csv(os.path.join(ext_files_path,\"cancer_gene_census_parsed.tsv\"), sep='\\t')\n",
    "cgc_genes = cgc_genes[cgc_genes['Somatic'] == 'yes']\n",
    "\n",
    "# Also read metadata data to add info to the cohort results \n",
    "clinical = pd.read_csv(\"../ext_files/all_cohort_clinical_groups.tsv\", sep='\\t')\n",
    "clinical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hemato_acronyms = ['aCML','AITL', 'AL', 'ALL','AML', 'APL', 'B-ALL', 'B-CLL', 'B-NHL','CLL','CML',\n",
    "                  'CMML', 'CNL', 'DLBCL', 'DLCL', 'ETP-ALL','JMML', 'L','MALT', 'MCL', 'MDS', 'MM',\n",
    "                  'NHL', 'NK/T', 'PMBL', 'pre-B ALL','sAML','SMZL','T-ALL','T-CLL','T-PLL']\n",
    "\n",
    "def filter_cgc_acronym(rw):\n",
    "    acronyms = set(rw['acronym_cgc'].split(\",\"))\n",
    "    test = acronyms.intersection(hemato_acronyms)\n",
    "    if len(test) == 0:\n",
    "        rw['keep'] = False\n",
    "    else:\n",
    "        rw['keep'] = True\n",
    "    return rw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cgc_genes = cgc_genes.apply(lambda x: filter_cgc_acronym(x), axis=1)\n",
    "cgc_genes_hemato = cgc_genes[cgc_genes['keep'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "black_list = intogen_black_list['known']\n",
    "black_list.extend(intogen_black_list['suspects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(black_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read results and manually inspect them to check for false positive suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff_drivers_cohort = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## In√©s manually defined black list\n",
    "suspects_FP = set(['CCDC190', 'RETSAT', 'TMEM67', 'RIBC2', 'KRTAP26-1', 'MAML2', 'TGM3', \n",
    "                   'MAGEL2', 'ISY1', 'MUC16', 'AP3D1', 'ACIN1', 'KLRF1', 'AGPAT2', 'RIMS2', \n",
    "                   'TOPBP1', 'CHIT1', 'NPY5R', 'OR4X1', 'CELSR2', 'ZNF274', 'NGEF', 'ISY1-RAB43', \n",
    "                   'ZFYVE26', 'PIK3R6', 'SV2A', 'ZNF780B', 'C10orf113', 'PABPC1', 'ARMC9', \n",
    "                   'SLITRK4', 'OR6Q1', 'CCDC93', 'GOLGA2', 'PTPRZ1', 'ST6GALNAC6', 'EME1', \n",
    "                   'PABPC3', 'MX2', 'PCDHB9', 'ZNF880', 'URI1', 'RTKN2', 'FAM71E2', 'PRR12', \n",
    "                   'SCAMP1', 'LTV1', 'AXDND1', 'GPATCH1', 'IARS2', 'IQSEC3','COL4A6', 'DCDC2B', \n",
    "                   'GPR61', 'IL13RA2', 'LUZP2', 'SLC7A9', 'TRPV3','ITK','OGFR', 'LNP1','TP53TG5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspects_FP.intersection(cgc_genes_hemato['Gene Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paths to results\n",
    "\n",
    "intogen_parent_path = \"\"\n",
    "\n",
    "intogen_subpaths = {'BALL_DUX4ERG_PED':\"26022020\",\n",
    "                'BALL_HYPER_PED':\"26022020\",\n",
    "                'BALL_HYPO_PED':\"26022020/\",\n",
    "                'BALL_IAMP21_PED':\"26022020\",\n",
    "                'BALL_INFANT_PED':\"03032020\",\n",
    "                'BALL_PH_LIKE_PED':\"26022020\",\n",
    "                'TALL_PED':\"03032020\",\n",
    "                'BALL_OSHIMA_PED':\"04032020\",\n",
    "                'TALL_OSHIMA_PED':\"04032020\",\n",
    "                'TALL_ADULT':\"29072020\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relate cohort intogen names with subtype annotation used in the analysis\n",
    "\n",
    "subtype_names = {'BALL_DUX4ERG_PED_PRY':\"DUX4-ERG\",\n",
    "                'BALL_HYPER_PED_PRY':\"Hyperdiploid\",\n",
    "                'BALL_HYPO_PED_PRY':\"Hypodiploid\",\n",
    "                'BALL_IAMP21_PED_PRY':\"iAMP21\",\n",
    "                'BALL_INFANT_PED_PRY':\"Infant_MLL-R\",\n",
    "                'BALL_PH_LIKE_PED_PRY':\"PHALL\",\n",
    "                'TALL_PED_PRY':\"TALL_Pediatric_pry\",\n",
    "                'BALL_OSHIMA_PED_PRY':\"BALL_Pediatric_WXS_pry\",\n",
    "                'TALL_OSHIMA_PED_PRY':\"TALL_Pediatric_WXS_pry\",\n",
    "                'BALL_OSHIMA_PED_REL':\"BALL_Pediatric_WXS_rel\",\n",
    "                'TALL_OSHIMA_PED_REL':\"TALL_Pediatric_WXS_rel\",\n",
    "                'TALL_ADULT_PRY':\"TALL_Adult_pry\",\n",
    "                'TALL_ADULT_REL':\"TALL_Adult_rel\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read results of the combination of methods of intogen\n",
    "\n",
    "for k,v in intogen_subpaths.items():\n",
    "    files = glob.glob(os.path.join(intogen_parent_path, v,'combination', k+'*.05.out.gz'))\n",
    "    for f in files:\n",
    "        type_leuk = k.split(\"_\")[0]\n",
    "        cohort = f.split(\"/\")[-1].replace(\".05.out.gz\", \"\")\n",
    "        stage = f.split(\"/\")[-1].split(\"_\")[-1].replace(\".05.out.gz\", \"\")\n",
    "        clinical_subtype = clinical[clinical['SUBTYPE'] == subtype_names[cohort]].reset_index(drop=True)\n",
    "        df_original = pd.read_csv(f, compression='gzip', sep='\\t')\n",
    "        df = df_original[df_original['TIER'].isin([1,2])] # keep tier 1 and 2\n",
    "        df = df.append(df_original[(df_original['TIER'] == 3) & (df_original['SYMBOL'].isin(cgc_genes_hemato['Gene Symbol'].unique()))], ignore_index=True) # only cancer genes of hematopoietic cancers in CGC \n",
    "        df = df.append(df_original[(df_original['TIER'] == 4) & (df_original['SYMBOL'].isin(cgc_genes_hemato['Gene Symbol'].unique()))], ignore_index=True) # only cancer genes of hematopoietic cancers in CGC\n",
    "        df_filt = df[~df['SYMBOL'].isin(black_list)] # remove genes from black list of any tier\n",
    "        df_filt = df_filt[['SYMBOL', 'TIER', 'ROLE']]\n",
    "        df_filt['SUBTYPE'] = subtype_names[cohort]\n",
    "        df_filt['SUBTYPE_LABEL'] = clinical_subtype.loc[0, 'SUBTYPE_LABEL']\n",
    "        df_filt['TYPE'] = clinical_subtype.loc[0, 'TYPE']\n",
    "        df_filt['STAGE'] = stage\n",
    "        dff_drivers_cohort = dff_drivers_cohort.append(df_filt, ignore_index=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff_drivers_cohort['STAGE'] = dff_drivers_cohort['STAGE'].replace(\"PRY\", \"primary\")\n",
    "dff_drivers_cohort['STAGE'] = dff_drivers_cohort['STAGE'].replace(\"REL\", \"relapse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the FP suspects are not even in cancer mine\n",
    "suspects_FP.difference(set(cancer_mine['gene_normalized'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from those in cancer mine most are not related to any hematological neoplasms \n",
    "cancer_mine[cancer_mine['gene_normalized'].isin(suspects_FP)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally filter the manually checked FP suspects\n",
    "dff_drivers_cohort = dff_drivers_cohort[~dff_drivers_cohort['SYMBOL'].isin(suspects_FP)]\n",
    "dff_drivers_cohort['SYMBOL'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PRIMARY AND RELAPSE CHINESE COHORT\n",
    "\n",
    "chin_wgs_into_run = os.path.join(intogen_parent_path, \"18032020\", \"combination\")\n",
    "\n",
    "#ALL PRIMARY \n",
    "df_original = pd.read_csv(os.path.join(chin_wgs_into_run,\"TALL_CHINESE_PRY.05.out.gz\"), compression='gzip', sep='\\t')\n",
    "df = df_original[df_original['TIER'].isin([1,2])]\n",
    "df = df.append(df_original[(df_original['TIER'] == 3) & (df_original['SYMBOL'].isin(cgc_genes_hemato['Gene Symbol'].unique()))], ignore_index=True)\n",
    "df = df.append(df_original[(df_original['TIER'] == 4) & (df_original['SYMBOL'].isin(cgc_genes_hemato['Gene Symbol'].unique()))], ignore_index=True)\n",
    "df_filt = df[~df['SYMBOL'].isin(black_list)] # general one of IntoGen\n",
    "df_filt = df_filt[~df_filt['SYMBOL'].isin(suspects_FP)] # manually filtered FP candidates\n",
    "df_filt = df_filt[['SYMBOL', 'TIER', 'ROLE']]\n",
    "df_filt['SUBTYPE'] = \"TALL_ped\"\n",
    "df_filt['SUBTYPE_LABEL'] = \"ALL Pediatric Chinese Study\"\n",
    "df_filt['STAGE'] = 'primary'\n",
    "df_filt['TYPE'] = \"TALL\"\n",
    "dff_drivers_cohort = dff_drivers_cohort.append(df_filt, ignore_index=True, sort=False)\n",
    "\n",
    "#ALL RELAPSE\n",
    "df_original = pd.read_csv(os.path.join(chin_wgs_into_run,\"TALL_CHINESE_REL.05.out.gz\"), compression='gzip', sep='\\t')\n",
    "df = df_original[df_original['TIER'].isin([1,2])]\n",
    "df = df.append(df_original[(df_original['TIER'] == 3) & (df_original['SYMBOL'].isin(cgc_genes_hemato['Gene Symbol'].unique()))], ignore_index=True)\n",
    "df = df.append(df_original[(df_original['TIER'] == 4) & (df_original['SYMBOL'].isin(cgc_genes_hemato['Gene Symbol'].unique()))], ignore_index=True)\n",
    "df_filt = df[~df['SYMBOL'].isin(black_list)] # general one of IntoGen\n",
    "df_filt = df_filt[~df_filt['SYMBOL'].isin(suspects_FP)] # manually filtered FP candidates\n",
    "df_filt = df_filt[['SYMBOL', 'TIER', 'ROLE']]\n",
    "df_filt['SUBTYPE'] = \"TALL_ped\"\n",
    "df_filt['SUBTYPE_LABEL'] = \"ALL Pediatric Chinese Study\"\n",
    "df_filt['STAGE'] = 'relapse'\n",
    "df_filt['TYPE'] = \"TALL\"\n",
    "dff_drivers_cohort = dff_drivers_cohort.append(df_filt, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete intogen list with literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_lite = pd.read_csv(\"../ext_files/literature/mutations_lite.tsv\", sep='\\t')\n",
    "df_list_lite['ROLE'] = df_list_lite['ROLE'].apply(lambda x: \"Act\" if x == \"act\" else x)\n",
    "df_list_lite['ROLE'] = df_list_lite['ROLE'].apply(lambda x: \"LoF\" if x == \"lof\" else x)\n",
    "df_list_lite['ROLE'] = df_list_lite['ROLE'].apply(lambda x: \"LoF\" if x == \"lof \" else x)\n",
    "df_list_lite['SUBTYPE'] = 'literature'\n",
    "df_list_lite.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join both\n",
    "df_final_list = dff_drivers_cohort[['SYMBOL', 'ROLE', 'SUBTYPE', 'SUBTYPE_LABEL']].copy()\n",
    "df_final_list = df_final_list.append(df_list_lite[['SYMBOL', 'ROLE', 'SUBTYPE']], ignore_index=True, sort=False)\n",
    "\n",
    "# correct NOTCH1\n",
    "df_final_list['ROLE'] = df_final_list.apply(lambda x: 'Act' if x['SYMBOL'] == 'NOTCH1' else x['ROLE'], axis=1)\n",
    "df_final_list[df_final_list['SYMBOL'] == 'NOTCH1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_list[['SYMBOL', 'ROLE']].drop_duplicates().groupby('SYMBOL').count().sort_values(by='ROLE',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct for wrong roles of genes\n",
    "\n",
    "print(len(df_final_list))\n",
    "grps_genes = df_final_list.groupby('SYMBOL')\n",
    "\n",
    "df_final_list = pd.DataFrame()\n",
    "\n",
    "for g in grps_genes.groups:\n",
    "    df_gene = grps_genes.get_group(g)\n",
    "    if (len(df_gene['ROLE'].unique()) > 1) and ('literature' in df_gene['SUBTYPE'].tolist()):\n",
    "        trusted_role = df_gene[df_gene['SUBTYPE'] == 'literature'].reset_index()\n",
    "        df_gene['ROLE'] = trusted_role.loc[0, 'ROLE'] \n",
    "        df_final_list = df_final_list.append(df_gene, ignore_index=True, sort=False)\n",
    "    else:\n",
    "        if (len(df_gene['ROLE'].unique()) > 1):\n",
    "            print(df_gene)\n",
    "            df_final_list = df_final_list.append(df_gene, ignore_index=True, sort=False)\n",
    "        else:\n",
    "            df_final_list = df_final_list.append(df_gene, ignore_index=True, sort=False)\n",
    "print(len(df_final_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GO terms by REACTOME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reactome = pd.read_csv(\"../ext_files/process_intogen/annotations/Ensembl2Reactome.txt\", sep='\\t',\n",
    "                      names=['ENSEMBL', 'STH', 'PATH', 'PATHWAY_REACTOME', 'STH2', 'ORGANISM'])\n",
    "reactome = reactome[reactome['STH2'] == 'TAS']\n",
    "reactome = reactome[reactome['ORGANISM'] == 'Homo sapiens']\n",
    "\n",
    "biomart = pd.read_csv(\"../ext_files/mart_export_grch37.txt\", sep='\\t')\n",
    "biomart = biomart[['Gene stable ID', 'Gene name']]\n",
    "biomart.rename(columns={'Gene stable ID':'ENSEMBL', 'Gene name':'SYMBOL'}, inplace=True)\n",
    "\n",
    "all_go_terms = biomart.merge(reactome[['ENSEMBL', 'PATHWAY_REACTOME']].drop_duplicates(), how='left', on='ENSEMBL')\n",
    "all_go_terms = all_go_terms[['SYMBOL', 'PATHWAY_REACTOME']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PANCAN ATLAS pathway list from supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathway_list = pd.read_excel(\"../ext_files/process_intogen/annotations/supp_from_paper_pathwayPANCAN.xlsx\", sheet_name=\"Table S2\", skiprows=[0,1,2])\n",
    "pathway_list = pathway_list[['Gene','Pathway']].drop_duplicates()\n",
    "pathway_list.rename(columns={'Gene':'SYMBOL', 'Pathway':'PATHWAY_PANCAN'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathway_list = pathway_list[['Gene','Pathway']].drop_duplicates()\n",
    "pathway_list.rename(columns={'Gene':'SYMBOL', 'Pathway':'PATHWAY_PANCAN'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PANTHER PATHWAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../ext_files/process_intogen/annotations/analysis_panther_pathways.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panther_results_gene = pd.DataFrame()\n",
    "\n",
    "for r in data['overrepresentation']['group']:\n",
    "    try:\n",
    "        if type (r['result']['input_list']['mapped_id_list']['mapped_id']) == list:\n",
    "            for gene in r['result']['input_list']['mapped_id_list']['mapped_id']:\n",
    "                panther_results_gene = panther_results_gene.append({'SYMBOL':gene, 'PATHWAY_PANTHER':r['result']['term']['label']}, \n",
    "                                                               ignore_index=True) \n",
    "        else:\n",
    "            panther_results_gene = panther_results_gene.append({'SYMBOL':r['result']['input_list']['mapped_id_list']['mapped_id'], \n",
    "                                                                'PATHWAY_PANTHER':r['result']['term']['label']}, \n",
    "                                                               ignore_index=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "panther_results_gene.drop_duplicates(inplace=True)\n",
    "panther_results_gene.sort_values(by=[\"SYMBOL\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check individually\n",
    "gene = 'CSF2RA'\n",
    "print(panther_results_gene[panther_results_gene['SYMBOL'] == gene])\n",
    "print(pathway_list[pathway_list['SYMBOL'] == gene])\n",
    "all_go_terms[all_go_terms['SYMBOL'] == gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panther_results_gene.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_go_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer_gene_annotated = df_final_list[['SYMBOL']].merge(all_go_terms, how='left', on=['SYMBOL'])\n",
    "cancer_gene_annotated = cancer_gene_annotated.merge(pathway_list, how='left', on=['SYMBOL'])\n",
    "cancer_gene_annotated = cancer_gene_annotated.merge(panther_results_gene, how='left', on=['SYMBOL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cancer_gene_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are many rows out of the merge of all the annotation sources we prioritize panther > pancan > reactome to have a reduced list of annotations and after we manually uniform them in one term that makes sense even thought the source of information is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_pathway = pd.DataFrame()\n",
    "\n",
    "for gene in df_final_list['SYMBOL'].unique():\n",
    "    gene_pancan = pathway_list[pathway_list['SYMBOL'] == gene].reset_index(drop=True)\n",
    "    gene_panther = panther_results_gene[panther_results_gene['SYMBOL'] == gene].reset_index(drop=True)\n",
    "    gene_panther['PATHWAY_PANTHER'] = gene_panther['PATHWAY_PANTHER'].replace(\"UNCLASSIFIED\", np.nan)\n",
    "    gene_panther = gene_panther.dropna()\n",
    "    gene_reactome = all_go_terms[all_go_terms['SYMBOL'] == gene].reset_index(drop=True)\n",
    "    \n",
    "#    \"signaling pathway\"\n",
    "    \n",
    "    if gene_panther.empty == False:\n",
    "        if len(gene_panther) == 1:\n",
    "            gene_pathway = gene_pathway.append({'SYMBOL':gene, 'PATHWAY':gene_panther.loc[0,'PATHWAY_PANTHER'], \n",
    "                                            'PATHWAY_SOURCE':'PANTHER'}, ignore_index=True, sort=False)\n",
    "        else:\n",
    "            gene_panther_subset = gene_panther[gene_panther['PATHWAY_PANTHER'].str.contains(\"signaling pathway\")] # prioritize signaling pathways over any other annotation of biological processes\n",
    "            if len(gene_panther_subset) == 0:\n",
    "                for i,rw in gene_panther.iterrows():\n",
    "                    gene_pathway = gene_pathway.append({'SYMBOL':gene, 'PATHWAY':gene_panther.loc[i,'PATHWAY_PANTHER'], \n",
    "                                            'PATHWAY_SOURCE':'PANTHER'}, ignore_index=True, sort=False)\n",
    "            else:\n",
    "                for i,rw in gene_panther_subset.iterrows():\n",
    "                    gene_pathway = gene_pathway.append({'SYMBOL':gene, 'PATHWAY':gene_panther_subset.loc[i,'PATHWAY_PANTHER'], \n",
    "                                            'PATHWAY_SOURCE':'PANTHER'}, ignore_index=True, sort=False)\n",
    "    else:\n",
    "        if gene_pancan.empty == False:\n",
    "            gene_pathway = gene_pathway.append({'SYMBOL':gene, 'PATHWAY':gene_pancan.loc[0,'PATHWAY_PANCAN'], \n",
    "                                                'PATHWAY_SOURCE':'PANCAN_PAPER'}, \n",
    "                                               ignore_index=True, sort=False)\n",
    "        else:\n",
    "            if gene_reactome.empty == False:\n",
    "                for i,rw in gene_reactome.iterrows():\n",
    "                    gene_pathway = gene_pathway.append({'SYMBOL':gene, 'PATHWAY':gene_reactome.loc[i,'PATHWAY_REACTOME'], \n",
    "                                                'PATHWAY_SOURCE':'REACTOME'}, \n",
    "                                               ignore_index=True, sort=False)\n",
    "            else:\n",
    "                gene_pathway = gene_pathway.append({'SYMBOL':gene, 'PATHWAY':np.nan, \n",
    "                                                'PATHWAY_SOURCE':np.nan}, \n",
    "                                               ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually decide for repeated rows (genes) and use GeneCards (https://www.genecards.org/) \n",
    "# to unify terms and complete empty information\n",
    "print(len(gene_pathway))\n",
    "gene_pathway.to_excel(\"../intermediate_files/driver_candidate_gene_pathways.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read unified and revised biological processes\n",
    "bio_proces = pd.read_csv(\"../intermediate_files/driver_candidate_gene_pathways.csv\",\n",
    "                         sep='\\t')\n",
    "bio_proces.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_final_list))\n",
    "df_final_list = df_final_list.merge(bio_proces, on='SYMBOL', how='left')\n",
    "print(len(df_final_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results of this can be found in Table S3\n",
    "out_path = \n",
    "df_final_list.to_csv(os.path.join(out_path, \"cancer_genes_ALL.csv\"), sep='\\t', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:noncoding]",
   "language": "python",
   "name": "conda-env-noncoding-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
