{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates one list of NOTCH1 mutations of the TALL cohorts (ADULT TALL AECC PROJECT, PEDIATRIC TALL WXS (Oshima et al., 2016; PNAS), PEDIATRIC ALL (Li et al., 2019, Blood)) to map the mutations to the exons. After, the needle plot figure can be done with NOTCH1_needle_plot.ipynb in ../notebook_figures\n",
    "\n",
    "This piece of code relies on a worspace directory structure such as \n",
    "```\n",
    "cohort/\n",
    "\tpatientID/\n",
    "\t\tDxTumorID_vs_normalID/\n",
    "\t\tReTumorID_vs_normalID/ (sometimes)\n",
    "\n",
    "```\n",
    " patientID, DxTumorID etc can be found in ../ext_files/all_cohort_clinical_groups.tsv\n",
    " \n",
    " Be aware that the maf files used to get the NOTCH1 mutations are the ones resulted from step 3 in the filtering steps. In this piece of code are called:\n",
    " ```\n",
    " - 'Strelka_'+TumorID_vs_normalID+'_somatic_snvs_sh_checked.maf'\n",
    " - 'Strelka_'+TumorID_vs_normalID+'_somatic_indels_sh.maf'\n",
    " - 'Strelka_'+TumorID_vs_normalID+'_somatic_mnvs_sh.maf'\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ[\"PATH\"] = os.path.dirname(sys.executable) + os.pathsep + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pybedtools\n",
    "from aux_functions import read_vcf,get_three_subsets\n",
    "from aux_data_in_pyvar import PATS_DIRS\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FUNCTIONS\n",
    "def map_muts(df_muts, df_gene):\n",
    "    df_muts[['#CHROM', 'REF', 'ALT']] = df_muts[['#CHROM', 'REF', 'ALT']].astype(str)\n",
    "    df_muts['POS'] = df_muts['POS'].astype(int)\n",
    "    \n",
    "    df_gene['#CHROM'] = df_gene['#CHROM'].astype(str)\n",
    "    df_gene[['START', 'END']] = df_gene[['START', 'END']].astype(int)\n",
    "    \n",
    "    muts = pybedtools.BedTool.from_dataframe(df_muts[['#CHROM', 'POS', 'POS','REF', 'ALT']])\n",
    "    gene_coords = pybedtools.BedTool.from_dataframe(df_gene[['#CHROM', 'START', 'END']])\n",
    "    \n",
    "    result = muts.intersect(gene_coords, loj = True)\n",
    "    merged = pd.read_table(result.fn, names=['#CHROM', 'POS', 'POS2','REF', 'ALT', 'chrom', 'start_gene', 'end_gene'])\n",
    "    \n",
    "    merged = merged[merged['start_gene'] == df_gene.loc[0,'START']]\n",
    "    merged[['#CHROM', 'REF', 'ALT']] = merged[['#CHROM', 'REF', 'ALT']].astype(str)\n",
    "    merged[['POS','start_gene']] = merged[['POS','start_gene']].astype(int)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "def filter_vep_results(df):\n",
    "\n",
    "    df_pass_annotation = pd.DataFrame()\n",
    "    df_inspection = pd.DataFrame()\n",
    "\n",
    "    grps = df.groupby(\"#Uploaded_variation\")\n",
    "\n",
    "    for g in grps.groups:\n",
    "        df_var = grps.get_group(g)\n",
    "        df_var.drop_duplicates(inplace=True)\n",
    "        df_var = df_var[df_var['SYMBOL'] == 'NOTCH1']\n",
    "        if len(df_var)>1:\n",
    "            df_var = df_var[df_var['CANONICAL'] == 'YES']\n",
    "            if len(df_var)>1:\n",
    "                df_inspection = df_inspection.append(df_var, ignore_index=True, sort=False)\n",
    "            else:\n",
    "                df_pass_annotation = df_pass_annotation.append(df_var, ignore_index=True, sort=False)\n",
    "        else:\n",
    "            df_pass_annotation = df_pass_annotation.append(df_var, ignore_index=True, sort=False)\n",
    "    print(df_inspection)\n",
    "    return df_pass_annotation\n",
    "\n",
    "\n",
    "def get_variant_columns(rw):\n",
    "    # get columns from id\n",
    "    rw['#CHROM'], pos, rw['REF'], rw['ALT'] = rw['#Uploaded_variation'].split(\"_\")\n",
    "    rw['POS'] = int(pos)\n",
    "    # filter polimorphisms\n",
    "    try:\n",
    "        af = float(rw['gnomADg_AF'])\n",
    "        if af >= 0.01:\n",
    "            rw['snp_remove'] = True\n",
    "        else:\n",
    "            rw['snp_remove'] = False\n",
    "    except ValueError:\n",
    "        rw['snp_remove'] = False\n",
    "    return rw\n",
    "\n",
    "\n",
    "def process_vep_results(path, muts):\n",
    "    try:\n",
    "        # read annotated vep variants\n",
    "        df = read_vcf(os.path.join(path, \"notch1_\"+muts+\"_anno_vep92.tab\"))\n",
    "        # get canonical\n",
    "        df = filter_vep_results(df)\n",
    "        # remove snps\n",
    "        df = df.apply(lambda x: get_variant_columns(x), axis=1)\n",
    "        df = df[df['snp_remove'] == False]\n",
    "        # read original input\n",
    "        df_original = pd.read_csv(os.path.join(path,\"notch1_\"+muts+\".tsv\"), sep='\\t')\n",
    "        df_original[['#CHROM', 'REF', 'ALT']] = df_original[['#CHROM', 'REF', 'ALT']].astype(str)\n",
    "        df_original[['POS']] = df_original[['POS']].astype(int)\n",
    "        # merge\n",
    "        notch1_muts = df_original.merge(df, how='left', on=['#CHROM', 'POS', 'REF', 'ALT'])\n",
    "        # remove unmapped mutations\n",
    "        notch1_muts.dropna(subset=['Existing_variation', 'IMPACT', 'DISTANCE', 'STRAND', 'FLAGS', 'SYMBOL',\n",
    "           'SYMBOL_SOURCE', 'HGNC_ID', 'CANONICAL', 'ENSP', 'SOURCE', 'EXON',\n",
    "           'INTRON', 'AFR_AF', 'AMR_AF', 'EAS_AF', 'EUR_AF', 'SAS_AF', 'CLIN_SIG',\n",
    "           'SOMATIC', 'PHENO', 'gnomADg', 'gnomADg_AF', 'gnomADg_NFE'], inplace=True)\n",
    "    except FileNotFoundError:\n",
    "            print(\"no {}\".format(muts))\n",
    "            notch1_muts = pd.DataFrame()\n",
    "    return notch1_muts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-VEP ONLY NOTCH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clinical data\n",
    "cohort = 'ADULT TALL AECC PROJECT'\n",
    "\n",
    "info_clinical = pd.read_csv(\"../ext_files/all_cohort_clinical_groups.tsv\", sep='\\t')\n",
    "info_clinical['PATIENT'] = info_clinical.apply(lambda x: 'oshima_pat_'+x['PATIENT'] if x['COHORT']=='PEDIATRIC TALL WXS (Oshima et al., 2016; PNAS)' else x['PATIENT'], axis=1)\n",
    "info_clinical_cohort = info_clinical[info_clinical['COHORT'] == cohort]\n",
    "\n",
    "info_clinical = info_clinical[info_clinical['COHORT'].isin(['ADULT TALL AECC PROJECT',  'PEDIATRIC TALL WXS (Oshima et al., 2016; PNAS)'])]\n",
    "info_clinical = info_clinical[info_clinical['PATIENT'] != 'oshima_pat_28']\n",
    "\n",
    "# Go to the supplementary materials of Li et al., 2020 PMID: 31697823 and make a dataframe with the clinical information\n",
    "# like the one in Additional file 2 Table S2 of the paper\n",
    "info_paper_blood = pd.read_csv(\"\", sep='\\t')\n",
    "info_paper_blood = info_paper_blood[info_paper_blood['TYPE'] == 'TALL'] \n",
    "\n",
    "info_clinical = info_clinical.append(info_paper_blood, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info_clinical['COHORT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#where mafs of mutationa are. Paths of Adult patients are given with PATS_DIRS dictionary since each\n",
    "# batch of sequenced patients is in a different folder\n",
    "in_dir = \"\" \n",
    "out_dir = \"\" #per cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTCH1 length\n",
    "notch1_gene = pd.DataFrame()\n",
    "notch1_gene = notch1_gene.append({\"#CHROM\":'9',\n",
    "\"START\":139388896,\n",
    "\"END\":139440314}, ignore_index=True)\n",
    "notch1_gene[['START', 'END']] = notch1_gene[['START', 'END']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_snvs_all = pd.DataFrame()\n",
    "df_indels_all = pd.DataFrame()\n",
    "df_mnvs_all = pd.DataFrame()\n",
    "\n",
    "for i, rw in info_clinical_cohort.iterrows():\n",
    "    \n",
    "    if rw['COHORT'] == \"ADULT TALL AECC PROJECT\":\n",
    "        in_dir = PATS_DIRS[rw['PATIENT']]\n",
    "    \n",
    "    # read maf for each type of mutation\n",
    "    try:\n",
    "        df_snvs = pd.read_csv(os.path.join(in_dir, rw['PATIENT'], rw['COMPARISON'], \n",
    "                                           'Strelka_'+rw['COMPARISON']+'_somatic_snvs_sh_checked.maf'), sep='\\t')\n",
    "        df_snvs['#CHROM'] = df_snvs['#CHROM'].astype(str) \n",
    "        df_indels = pd.read_csv(os.path.join(in_dir, rw['PATIENT'], rw['COMPARISON'], \n",
    "                                           'Strelka_'+rw['COMPARISON']+'_somatic_indels_sh.maf'), sep='\\t')\n",
    "        df_indels['#CHROM'] = df_indels['#CHROM'].astype(str) \n",
    "        df_mnvs = pd.read_csv(os.path.join(in_dir, rw['PATIENT'], rw['COMPARISON'], \n",
    "                                           'Strelka_'+rw['COMPARISON']+'_somatic_mnvs_sh_checked.maf'), sep='\\t')\n",
    "        df_mnvs['#CHROM'] = df_mnvs['#CHROM'].astype(str) \n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    # get muts in chrom 9\n",
    "    df_snvs = df_snvs[df_snvs['#CHROM'] == '9']\n",
    "    df_indels = df_indels[df_indels['#CHROM'] == '9']\n",
    "    df_mnvs = df_mnvs[df_mnvs['#CHROM'] == '9']\n",
    "    \n",
    "    # map muts to notch1 gene\n",
    "    df_snvs_map = map_muts(df_snvs, notch1_gene)\n",
    "    df_indels_map = map_muts(df_indels, notch1_gene)\n",
    "    df_mnvs_map = map_muts(df_mnvs, notch1_gene)\n",
    "    \n",
    "    df_snvs_map = df_snvs_map[['#CHROM', 'POS', 'REF', 'ALT']].merge(df_snvs, how='inner', on=['#CHROM', 'POS', 'REF', 'ALT'])\n",
    "    df_indels_map = df_indels_map[['#CHROM', 'POS', 'REF', 'ALT']].merge(df_indels, how='inner', on=['#CHROM', 'POS', 'REF', 'ALT'])\n",
    "    df_mnvs_map = df_mnvs_map[['#CHROM', 'POS', 'REF', 'ALT']].merge(df_mnvs, how='inner', on=['#CHROM', 'POS', 'REF', 'ALT'])\n",
    "    \n",
    "    #snvs\n",
    "    if df_snvs_map.empty == False:\n",
    "        df_snvs_map['ID'] = df_snvs_map.apply(lambda x: x['#CHROM']+'_'+str(x['POS'])+'_'+x['REF']+'_'+x['ALT'], axis=1)\n",
    "        df_snvs_map['COMPARISON'] = rw['COMPARISON']\n",
    "        df_snvs_all = df_snvs_all.append(df_snvs_map, ignore_index=True)\n",
    "    # indels\n",
    "    if df_indels_map.empty == False:\n",
    "        df_indels_map['ID'] = df_indels_map.apply(lambda x: x['#CHROM']+'_'+str(x['POS'])+'_'+x['REF']+'_'+x['ALT'], axis=1)\n",
    "        df_indels_map['COMPARISON'] = rw['COMPARISON'] \n",
    "        df_indels_all = df_indels_all.append(df_indels_map, ignore_index=True)\n",
    "    # mnvs\n",
    "    if df_mnvs_map.empty == False:\n",
    "        df_mnvs_map['ID'] = df_mnvs_map.apply(lambda x: x['#CHROM']+'_'+str(x['POS'])+'_'+x['REF']+'_'+x['ALT'], axis=1)\n",
    "        df_mnvs_map['COMPARISON'] = rw['COMPARISON'] \n",
    "        df_mnvs_all = df_mnvs_all.append(df_mnvs_map, ignore_index=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if df_snvs_all.empty == False:\n",
    "     df_snvs_all[['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT',\n",
    "        'NORMAL', 'TUMOR', 'DP_tumor', 't_alt_reads', 't_ref_reads',\n",
    "        'DP_normal', 'n_alt_reads', 'n_ref_reads', 'mut_type', 'GT_normal',\n",
    "        'GT_tumor','COMPARISON']].to_csv(os.path.join(out_dir,\"notch1_snvs.tsv\"), sep='\\t', index=False)\n",
    "if df_indels_all.empty == False:\n",
    "     df_indels_all[['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT',\n",
    "        'NORMAL', 'TUMOR', 'DP_tumor', 't_alt_reads', 't_ref_reads',\n",
    "        'DP_normal', 'n_alt_reads', 'n_ref_reads', 'mut_type', 'GT_normal',\n",
    "        'GT_tumor','COMPARISON']].to_csv(os.path.join(out_dir,\"notch1_indels.tsv\"), sep='\\t', index=False)\n",
    "if df_mnvs_all.empty == False:\n",
    "     df_mnvs_all[['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT',\n",
    "        'NORMAL', 'TUMOR', 'DP_tumor', 't_alt_reads', 't_ref_reads',\n",
    "        'DP_normal', 'n_alt_reads', 'n_ref_reads', 'mut_type', 'GT_normal',\n",
    "        'GT_tumor','COMPARISON']].to_csv(os.path.join(out_dir,\"notch1_mnvs.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN VEP\n",
    "\n",
    "\n",
    "```\n",
    "source activate vep92\n",
    "\n",
    "\n",
    "vep -i notch1_snvs.tsv -o STDOUT -tab --assembly GRCh37 --no_stats --cache --symbol --protein --numbers --canonical --offline --af_1kg --dir /workspace/datasets/vep --custom /workspace/datasets/gnomad/gnomad.genomes.r2.0.1.sites.noVEP.vcf.gz,gnomADg,vcf,exact,0,AF,NFE > notch1_snvs_anno_vep92.tab\n",
    " \n",
    " \n",
    "vep -i notch1_indels.tsv -o STDOUT -tab --assembly GRCh37 --no_stats --cache --symbol --protein --numbers --canonical --offline --af_1kg --dir /workspace/datasets/vep --custom /workspace/datasets/gnomad/gnomad.genomes.r2.0.1.sites.noVEP.vcf.gz,gnomADg,vcf,exact,0,AF,NFE > notch1_indels_anno_vep92.tab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST VEP ONLY NOTCH1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## read NOTCH1 annotated mutations\n",
    "\n",
    "notch1_candidates = pd.DataFrame()\n",
    "\n",
    "mutation_types = ['snvs', 'indels', 'mnvs']\n",
    "\n",
    "in_dir = \"../intermediate_files/notch1_needle_muts/\"\n",
    "\n",
    "folder = 'adult_TALL'\n",
    "\n",
    "for muts in mutation_types:\n",
    "    path = os.path.join(in_dir, folder)\n",
    "    result = process_vep_results(path, muts)\n",
    "    if result.empty ==False:\n",
    "        result.drop(['FILTER','FORMAT','GT_normal','GT_tumor','INFO','NORMAL','QUAL','TUMOR'],axis=1, inplace=True)\n",
    "    notch1_candidates = notch1_candidates.append(result, ignore_index=True, sort=False)\n",
    "    \n",
    "folder = 'oshima_WXS_2016'\n",
    "\n",
    "for muts in mutation_types:\n",
    "    path = os.path.join(in_dir, folder)\n",
    "    result = process_vep_results(path, muts)\n",
    "    if result.empty ==False:\n",
    "        result.drop(['FILTER','FORMAT','GT_normal','GT_tumor','INFO','NORMAL','QUAL','TUMOR'],axis=1, inplace=True)\n",
    "    notch1_candidates = notch1_candidates.append(result, ignore_index=True, sort=False)   \n",
    "    \n",
    "folder = 'li_blood_2020'\n",
    "\n",
    "for muts in mutation_types:\n",
    "    path = os.path.join(in_dir, folder)\n",
    "    result = process_vep_results(path, muts)\n",
    "    notch1_candidates = notch1_candidates.append(result, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## muts protein affecting\n",
    "notch1_candidates = notch1_candidates[notch1_candidates['Consequence'] != 'synonymous_variant']\n",
    "notch1_candidates = notch1_candidates[notch1_candidates['Protein_position'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## annotate mutations with subset\n",
    "grps = info_clinical.groupby(\"PATIENT\")\n",
    "\n",
    "notch1_muts_subsets = pd.DataFrame()\n",
    "\n",
    "for g in grps.groups:\n",
    "   \n",
    "    pat_info = grps.get_group(g)\n",
    "    pat_info.sort_values(\"STAGE\", inplace=True)\n",
    "    pat_info.reset_index(drop=True, inplace=True)\n",
    "    com_pry = pat_info[pat_info['STAGE'] == 'primary']['COMPARISON'].unique()[0]\n",
    "    com_rel = pat_info[pat_info['STAGE'] == 'relapse']['COMPARISON'].unique()[0]\n",
    "    \n",
    "    pry_notch1 = notch1_candidates[notch1_candidates['COMPARISON'] == com_pry]\n",
    "    rel_notch1 = notch1_candidates[notch1_candidates['COMPARISON'] == com_rel]\n",
    "    \n",
    "    if (pry_notch1.empty == True) and (rel_notch1.empty == True):\n",
    "        continue\n",
    "    \n",
    "    pry_notch1['Variant'] = pry_notch1['ID']\n",
    "    rel_notch1['Variant'] = rel_notch1['ID']\n",
    "    \n",
    "    trunk, private_pry, private_rel = get_three_subsets(pry_notch1, rel_notch1)\n",
    "    \n",
    "    pry_notch1['PATIENT'] = g\n",
    "    rel_notch1['PATIENT'] = g\n",
    "    \n",
    "    pry_notch1['COHORT'] = pat_info['COHORT'].unique()[0]\n",
    "    rel_notch1['COHORT'] = pat_info['COHORT'].unique()[0]\n",
    "    \n",
    "    if pry_notch1.empty == False:\n",
    "        pry_notch1['subset'] = pry_notch1.apply(lambda x: 'shared' if x['Variant'] in trunk else 'private_primary', axis=1)\n",
    "        notch1_muts_subsets = notch1_muts_subsets.append(pry_notch1[['#CHROM', 'POS', 'REF', 'ALT', 'Consequence', \n",
    "                                                                 'SYMBOL', 'mut_type','EXON', 'Amino_acids',\n",
    "                                                                 'Protein_position', 'subset', 'Variant','PATIENT', 'COHORT']], ignore_index=True, sort= False)\n",
    "    if rel_notch1.empty == False:\n",
    "        print(g)\n",
    "        rel_notch1_subset = rel_notch1[rel_notch1['Variant'].isin(private_rel)]\n",
    "        rel_notch1_subset['subset'] = 'private_relapse'\n",
    "        notch1_muts_subsets = notch1_muts_subsets.append(rel_notch1_subset[['#CHROM', 'POS', 'REF', 'ALT', 'Consequence', \n",
    "                                                                 'SYMBOL', 'mut_type','EXON', 'Amino_acids',\n",
    "                                                                 'Protein_position', 'subset', 'Variant','PATIENT', 'COHORT']], ignore_index=True, sort= False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notch1_muts_subsets[['COHORT', 'PATIENT']].drop_duplicates().groupby('COHORT').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notch1_muts_subsets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notch1_muts_subsets.to_csv(os.path.join(in_dir, \"candidate_muts_notch1.tsv\"), sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:filter_pipeline]",
   "language": "python",
   "name": "conda-env-filter_pipeline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
