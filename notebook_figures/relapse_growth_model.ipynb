{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook calculates the doubling time of the T-cell lymphoblast population was estimated following a similar approach as in Li et al., 2020. This notebook also does Additional File 1 FigureS9 a and b with the trajectories of the relapse tumor growth and doubling time estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "from collections import OrderedDict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import curve_fit,minimize\n",
    "\n",
    "from aux_data_in_pyvar import config_rcparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_rcparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path = \"\" # path for the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FUNCTIONS\n",
    "\n",
    "def get_points(df):\n",
    "    \n",
    "    dict_patients = {}\n",
    "    dh = df.sort_values(by='days')\n",
    "    for i in df.index:\n",
    "        patient = df.loc[i, 'PATIENT']\n",
    "        days = df.loc[i, 'days']\n",
    "        blast_value = df.loc[i, 'blast ratio']\n",
    "        blast_bool = int(blast_value > 0.01)  # pseudo-count\n",
    "        blast_value = blast_value * blast_bool + 0.01 * (1 - blast_bool)\n",
    "        dict_patients[patient] = dict_patients.get(patient, []) + [(days, blast_value)]\n",
    "    return dict_patients\n",
    "\n",
    "\n",
    "def sigmoid(x, a):\n",
    "    \n",
    "    return 1 / (1 + np.exp((-1) * a * x / 100))\n",
    "\n",
    "def logsigmoid(x, a):\n",
    "    \n",
    "    return -np.log((1 + np.exp((-1) * a * x)))\n",
    "\n",
    "\n",
    "def cross_entropy(patients, shifts, a):\n",
    "    \n",
    "    \"\"\"\n",
    "    patients : dict of point pairs per patient\n",
    "    shifts   : dict of shifts per patients\n",
    "    a        : growth parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    for p in patients:\n",
    "        \n",
    "        y_initial = patients[p][0][1]\n",
    "        t_initial = patients[p][0][0]\n",
    "        y_final   = patients[p][1][1]\n",
    "        t_final   = patients[p][1][0]\n",
    "        \n",
    "        s = shifts[p]\n",
    "        \n",
    "        score += y_initial * np.log(sigmoid(t_initial - s, a))\n",
    "        score += (1 - y_initial) * np.log(1 - sigmoid(t_initial - s, a))\n",
    "        score += y_final * np.log(sigmoid(t_final - s, a))\n",
    "        score += (1 - y_final) * np.log(1 - sigmoid(t_final - s, a))\n",
    "        \n",
    "    return -score\n",
    "\n",
    "def cost_function(params):\n",
    "    \n",
    "    a = params[0]\n",
    "    shifts = {p: params[i + 1] for i, p in enumerate(set_patients)}\n",
    "    return cross_entropy(dict_patients, shifts, a)\n",
    "\n",
    "def partial_cost_function(a):\n",
    "    \"\"\"return another function letting the value of a fixed\"\"\"\n",
    "    \n",
    "    def func(shift_params):\n",
    "        \n",
    "        params = [a] + list(shift_params)\n",
    "        return cost_function(params)\n",
    "    \n",
    "    return func\n",
    "\n",
    "\n",
    "# setting the intial values for optimization\n",
    "def generate_random_shifts():\n",
    "    \n",
    "    return np.array([-200. + np.random.choice(range(400), size=1)[0] for p in set_patients])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get clinical data with days and pathologist blast measures\n",
    "path_to_tsv = \"\" # table from Additional file 1 Table S1\n",
    "df_clinical = pd.read_csv(path_to_tsv, sep='\\t')\n",
    "df_clinical.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data\n",
    "data = df_clinical[['Patient_id', 'Remission_sample_blasts', 'Relapse_sample_blasts','days_between_rem_rel']].dropna()\n",
    "data['Remission_sample_blasts'] = data['Remission_sample_blasts'].apply(lambda x: float(x.replace(\"<\", \"\")) if type(x) == str else float(x))\n",
    "data['Relapse_sample_blasts'] = data['Relapse_sample_blasts'].apply(lambda x: float(x.replace(\">\", \"\")) if type(x) == str else float(x))\n",
    "\n",
    "# PAT12 and PAT9 are clearly an outlier. Not used to fit the curve\n",
    "data = data[data['Patient_id'] != 'PAT12']\n",
    "data = data[data['Patient_id'] != 'PAT9']\n",
    "\n",
    "data_rem = data[['Patient_id', 'Remission_sample_blasts']]\n",
    "data_rem.rename(columns={'Remission_sample_blasts':\"% blast\", 'Patient_id':'PATIENT'}, inplace=True)\n",
    "data_rem['days'] = 0\n",
    "data_rel =  data[['Patient_id', 'Relapse_sample_blasts', 'days_between_rem_rel']]\n",
    "data_rel.rename(columns={'Relapse_sample_blasts':\"% blast\", 'days_between_rem_rel':\"days\",'Patient_id':'PATIENT'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "data = data_rem.copy()\n",
    "data = data.append(data_rel, ignore_index=True, sort=False)\n",
    "data.to_csv(\"../intermediate_files/data_points_relapse.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../intermediate_files/data_points_relapse.tsv'\n",
    "df = pd.read_csv(fn, sep='\\t')\n",
    "df['blast ratio'] = df['% blast'].values / 100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_patients\n",
    "\n",
    "dict_patients = get_points(df)\n",
    "dict_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting growth rate and time-shift simultaneously\n",
    "\n",
    "For each pair of data (time = initial or final) the initial estimate is not highly reliable. Consequently, by centering each pair first we are introducing quite a bit of error in the final fitting. \n",
    "\n",
    "Workaround: stadardize the time of the samples so that the initial and final estimates are well adjusted to some sigmoid of the form $\\sigma(t, a) = (1 + e^{-at})^{-1}$ and find out the MLE estimate for $a$, i.e., find $\\hat{a}$ and $S_i$ such that we minimize the cross-entropy:\n",
    "\n",
    "$$\\mathcal{L}(a;S_1,\\ldots,S_N; y_1,\\ldots, y_N) = \\\\ \\sum_{i=1}^N C(t_{i, \\texttt{initial}}, y_{i, \\texttt{initial}}) + C(t_{i, \\texttt{final}}, y_{i, \\texttt{final}}) = \\\\\n",
    "- \\sum_{i=1}^N y_{i, \\texttt{initial}} \\log \\left( \\sigma(t_{i, \\texttt{initial}} - S_i, a)\\right) + (1 - y_{i, \\texttt{initial}})\\log\\left(1 - \\sigma(t_{i, \\texttt{initial}} - S_i, a)\\right) \\\\ \n",
    "- \\sum_{i=1}^N y_{i, \\texttt{final}} \\log \\left( \\sigma(t_{i, \\texttt{final}} - S_i, a)\\right) + (1 - y_{i, \\texttt{final}})\\log\\left(1 - \\sigma(t_{i, \\texttt{final}} - S_i, a)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_patients = sorted(dict_patients.keys())\n",
    "set_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize using a straightforward optimization approach\n",
    "\n",
    "optimal_value = None\n",
    "optimal_a = None\n",
    "optimal_shifts = None\n",
    "\n",
    "with open(\"../intermediate_files/optimization_values.txt\", \"a\") as f:\n",
    "    for _ in range(1000):\n",
    "\n",
    "        initial_shift_params = generate_random_shifts()\n",
    "        initial_params = [np.random.choice(range(10))] + list(initial_shift_params)\n",
    "        res = minimize(cost_function, initial_params, options={'maxiter': 10000}, \n",
    "                       method='Nelder-Mead', tol=1e-10)\n",
    "        value = cost_function(res.x)\n",
    "        if (optimal_value is None) or (value < optimal_value):\n",
    "            optimal_value = value\n",
    "            optimal_a = res.x[0]\n",
    "            optimal_shifts = res.x[1:]\n",
    "            print(optimal_value, optimal_a, optimal_shifts)\n",
    "            f.write(\"{} {} {}\\n\".format(optimal_value, optimal_a, optimal_shifts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array = []\n",
    "y_array = []\n",
    "patients = []\n",
    "for i, p in enumerate(set_patients):\n",
    "    for (x, y) in dict_patients[p]:\n",
    "        x_array += [x - optimal_shifts[i]]\n",
    "        y_array += [y]\n",
    "        patients.append(p)\n",
    "day = np.array(x_array)\n",
    "blast = np.array(y_array)\n",
    "plt.scatter(day, blast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression again...\n",
    "\n",
    "x = np.array([np.ones_like(day), day])\n",
    "y = np.array(blast)\n",
    "logit = Logit(y, x.T)\n",
    "res = logit.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimators\n",
    "\n",
    "intercept, slope = res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = lambda arg: 1 / (1 + np.exp((-1) * (arg * slope + intercept)))\n",
    "plt.scatter(day, blast)\n",
    "x_vals = np.linspace(min(day), max(day), num=100)\n",
    "y_vals = list(map(probs, x_vals))\n",
    "plt.plot(x_vals, y_vals, c='r')\n",
    "plt.hlines(0.5, min(day), max(day), linestyles='dashed')\n",
    "plt.ylabel('blast ratio')\n",
    "plt.xlabel('time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doing it with randomized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "params = []\n",
    "day_list = []\n",
    "blast_list = []\n",
    "for _ in range(100):\n",
    "\n",
    "    rand_index = np.random.choice(np.arange(len(day)), size=len(day), replace=True)\n",
    "    day_rand = day[rand_index]\n",
    "    blast_rand = blast[rand_index]\n",
    "    day_list.append(list(day_rand))\n",
    "    blast_list.append(list(blast_rand))\n",
    "    x = np.array([np.ones_like(day_rand), day_rand])\n",
    "    y = np.array(blast_rand)\n",
    "    logit = Logit(y, x.T)\n",
    "    res = logit.fit()\n",
    "    params.append(res.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define color of points\n",
    "dicc_colors = {'PAT10':'#d73027',\n",
    "               'PAT11':'#f1b6da',\n",
    "               'PAT13':'#fddbc7',\n",
    "               'PAT14':'#80cdc1',\n",
    "               'PAT1':'#d38d5fff',\n",
    "               'PAT2':'#ffffbf',\n",
    "               'PAT3':'#f46d43',\n",
    "               'PAT4':'#66bd63',\n",
    "               'PAT6':'#74add1',\n",
    "               'PAT7':'#002255ff',\n",
    "               'PAT8':'#aaaaffff',\n",
    "               'PAT15':\"#d4ff2aff\",\n",
    "               'PAT18':'#668000ff',\n",
    "               'PAT19':'#d3bc5fff',\n",
    "               'PAT16':'#782167ff'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make figure of trajectories from bootstrap\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "\n",
    "for i, (intercept, slope) in enumerate(params):\n",
    "    probs = lambda arg: 1 / (1 + np.exp((-1) * (arg * slope + intercept)))\n",
    "    x_vals = np.linspace(-400, 400, num=100)\n",
    "    y_vals = list(map(probs, x_vals))\n",
    "    ax.plot(x_vals, y_vals, c='#e0e0e0', alpha=0.05)\n",
    "\n",
    "for i, pat in enumerate(patients):\n",
    "    ax.scatter(day[i], blast[i], c=dicc_colors[pat], label=pat, edgecolor='#4d4d4d', s=50,\n",
    "               zorder=3)\n",
    "ax.set_ylabel(\"lymphoblast proportion\")\n",
    "ax.set_xlabel(\"days\")\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "handles_singles = [handles[j] for j in range(1,len(set_patients)*2+1,2)]\n",
    "labels_singles = [labels[j] for j in range(1,len(set_patients)*2+1,2)]\n",
    "\n",
    "plt.legend(handles=handles_singles,bbox_to_anchor=(0.4, 1),prop={'size': 10},ncol=2)\n",
    "plt.title(\"Tumor growth trajectories in standardized time\", fontsize=14)\n",
    "\n",
    "plt.savefig(os.path.join(out_path,'fitting_logistic.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get values of doubling time from bootstrap\n",
    "\n",
    "values_doubling = list()\n",
    "\n",
    "for intercept, alpha in params:\n",
    "    values_doubling.append((np.log(2) / alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make figure\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,4))\n",
    "\n",
    "sns.boxplot(x=values_doubling, color='#e0e0e0', orient='v',ax=ax)\n",
    "\n",
    "ax.text(x=0.1, y=round(np.percentile(values_doubling, 25), 2)-0.55, s=round(np.percentile(values_doubling, 25), 2))\n",
    "ax.text(x=0.1, y=round(np.percentile(values_doubling, 75), 2)+0.1, s=round(np.percentile(values_doubling, 75), 2))\n",
    "ax.text(x=0, y=round(np.mean(values_doubling),2)+0.05, s=\"mean:{}\".format(round(np.mean(values_doubling),2)), ha='center')\n",
    "ax.set_ylabel(\"doubling time\")\n",
    "\n",
    "for i,box in enumerate(ax.artists):\n",
    "    box.set_edgecolor('black')\n",
    "    box.set_linewidth(0.5)\n",
    "    for j in range(i*5,i*5+5):\n",
    "        line = ax.lines[j]\n",
    "        line.set_color('black')\n",
    "        line.set_mfc('black')\n",
    "        line.set_mec('black')\n",
    "        line.set_linewidth(0.9)\n",
    "plt.title(\"Doubling time estimates \\n from bootstrapping\")\n",
    "plt.savefig(os.path.join(out_path,'doubling_time_measure.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write estimates in json for the following analysis (jupyter-nb )\n",
    "\n",
    "data = {}\n",
    "data['CI_upp'] = round(np.percentile(values_doubling, 75), 2) \n",
    "data['CI_down'] = round(np.percentile(values_doubling, 25), 2) \n",
    "data['mean'] = round(np.mean(values_doubling),2)\n",
    "print(data)\n",
    "\n",
    "with open('../intermediate_files/info_pop_cells.json', 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:filter_pipeline]",
   "language": "python",
   "name": "conda-env-filter_pipeline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
