{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs correlations between mutations attributable to clock-like signatures and the age of the patients. \n",
    "\n",
    "The plots and numbers of the linear regressions correspond to Figure 4a and Additional file 1 Figure S7 in the paper\n",
    "\n",
    "This piece of code relies on a workspace directory structure such as:\n",
    "```\n",
    "cohort/\n",
    "\tpatientID/\n",
    "\t\tDxTumorID_vs_normalID/\n",
    "\t\tReTumorID_vs_normalID/ (sometimes)\n",
    "\n",
    "```\n",
    " patientID, DxTumorID etc can be found in ../ext_files/all_cohort_clinical_groups.tsv\n",
    " \n",
    "Be aware that the filtered mafs with clonal classification and joined mutations after running the scripts in ```filter/```  have the following file name: ```TumorID_vs_normalID + _strelka_uniq_all_anno_vep92_categories_filt_snps_cluster.maf``` \n",
    ".This file name is used in the following code.\n",
    "\n",
    "PATS_DIRS is a dictionary with the path to the patient folder where the MAF files are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ[\"PATH\"] = os.path.dirname(sys.executable) + os.pathsep + os.environ[\"PATH\"]\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import glob\n",
    "\n",
    "from aux_functions import stage_mapping, get_context_rev,add_pyrimidine_type, df_to_dict,count_variant_type, get_muts_x_signature\n",
    "from aux_data_in_pyvar import PATS_DIRS, COLORS_SIGNATURES, COLORS_SUBTYPES, config_rcparams\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_rcparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clonal_x_signature_patient(path_fitting, clinical):\n",
    "    \n",
    "    signature_subsets = pd.DataFrame()\n",
    "    \n",
    "    fitting_results = pd.read_csv(os.path.join(path_fitting, \"signatures_weight.csv\"), sep='\\t')\n",
    "    \n",
    "    for pat in fitting_results['sample_id']:\n",
    "        \n",
    "        df_pat = pd.DataFrame()\n",
    "        \n",
    "        clinical_pat = clinical[clinical['PATIENT'] == pat].reset_index()\n",
    "        com_pry = clinical_pat[clinical_pat['STAGE'] == 'primary']['COMPARISON'].tolist()[0]\n",
    "        com_rel = clinical_pat[clinical_pat['STAGE'] == 'relapse']['COMPARISON'].tolist()[0]\n",
    "\n",
    "        df_pry = pd.read_table(os.path.join(PATS_DIRS[pat], pat, com_pry,\n",
    "                                            com_pry+'_strelka_uniq_all_anno_vep92_categories_filt_snps_cluster.maf'),\n",
    "                               sep='\\t',low_memory=False)\n",
    "\n",
    "        df_rel = pd.read_table(os.path.join(PATS_DIRS[pat], pat, com_rel,\n",
    "                                            com_rel+'_strelka_uniq_all_anno_vep92_categories_filt_snps_cluster.maf'), \n",
    "                            sep='\\t',low_memory=False)\n",
    "\n",
    "        # GET CLONALS and SNVS\n",
    "        df_pry = df_pry[df_pry['mut_type'] == 'snv']\n",
    "        df_rel = df_rel[df_rel['mut_type'] == 'snv']\n",
    "\n",
    "        # SEPARATE CLONALS SUBCLONALS\n",
    "      \n",
    "        df_pry = df_pry[df_pry['clonal_classification'] == 'clonal']\n",
    "        df_rel = df_rel[df_rel['clonal_classification'] == 'clonal']\n",
    "\n",
    "        # GET SUBSETS\n",
    "        all_pry_variants = set(df_pry['Variant'].unique())\n",
    "        all_rel_variants = set(df_rel['Variant'].unique())\n",
    "\n",
    "        shared_variants = all_pry_variants.intersection(all_rel_variants)\n",
    "        private_pry_variants = all_pry_variants.difference(shared_variants)\n",
    "        private_rel_variants = all_rel_variants.difference(shared_variants) \n",
    "\n",
    "        df_shared = df_pry[df_pry['Variant'].isin(shared_variants)]\n",
    "        df_private_pry = df_pry[df_pry['Variant'].isin(private_pry_variants)]\n",
    "        df_private_rel = df_rel[df_rel['Variant'].isin(private_rel_variants)]\n",
    "\n",
    "        for signature in ['SBS1', 'SBS5']: # clock like\n",
    "\n",
    "            count_pp, count_pr, count_sh = get_muts_x_signature(sh=df_shared, pp=df_private_pry, \n",
    "                                                            pr=df_private_rel, pat=pat, sig=signature, \n",
    "                                                            prob_file_path=path_fitting)\n",
    "\n",
    "            df_pat.set_value(index=0, col='MUTS_CLONAL_'+signature, value=count_pp+count_sh)\n",
    "            df_pat.set_value(index=1, col='MUTS_CLONAL_'+signature, value=count_pr+count_sh)  \n",
    "                \n",
    "            df_pat.set_value(index=0, col='STAGE', value=\"primary\")\n",
    "            df_pat.set_value(index=1, col='STAGE', value=\"relapse\") \n",
    "\n",
    "        df_pat['PATIENT'] = pat\n",
    "        signature_subsets = signature_subsets.append(df_pat, ignore_index=True)\n",
    "    return signature_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FUNCTIONS\n",
    "\n",
    "def get_clonal_x_signature_sample(path_fitting, inputt):\n",
    "    \n",
    "    df_sig = pd.read_csv(os.path.join(path_fitting,'signatures_weight.csv'), sep='\\t')\n",
    "    prob = pd.read_csv(os.path.join(path_fitting, \"mutation_sign_prob.tsv\"), sep='\\t')\n",
    "    \n",
    "    signature_subsets = pd.DataFrame()\n",
    "    for i,rw in df_sig.iterrows():\n",
    "        ids = rw['sample_id']\n",
    "        signatures = [col for col in rw.index if 'SBS' in col]\n",
    "        \n",
    "        if \"_vs_\" in ids:\n",
    "            # read maf\n",
    "            path= glob.glob(os.path.join(in_maf, '*/'+ids,ids+\"_strelka_uniq_all_anno_vep92_categories_filt_snps_cluster.maf\"))\n",
    "            maf = pd.read_csv(path[0], sep='\\t',low_memory=False)\n",
    "        else: \n",
    "            if type(inputt) == collections.OrderedDict:\n",
    "                in_maf = inputt[ids]\n",
    "            else:\n",
    "                in_maf = inputt\n",
    "            path= glob.glob(os.path.join(in_maf, ids,\"*_vs_*/*_strelka_uniq_all_anno_vep92_categories_filt_snps_cluster.maf\"))\n",
    "            maf = pd.read_csv(path[0], sep='\\t',low_memory=False)\n",
    "        # filter\n",
    "        maf = maf[maf['mut_type'] == 'snv']\n",
    "        maf = maf[maf['clonal_classification'] == 'clonal']\n",
    "\n",
    "        # get signature probabilities by context\n",
    "        prob_pat = prob[prob['Sample'] == ids].set_index('Mutation_type')\n",
    "        prob_pat.index.name=None\n",
    "\n",
    "        for sig in signatures:\n",
    "            dicc_muts = df_to_dict(maf)\n",
    "            count_df = 0\n",
    "            for cntxt, count in dicc_muts.items():\n",
    "                prob_sig = prob_pat.loc[cntxt, sig]\n",
    "                count_df = count_df + count*prob_sig\n",
    "            signature_subsets.set_value(index=ids, col='MUTS_CLONAL_'+sig, value=count_df)\n",
    "    return signature_subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PLOT FUNCTIONS\n",
    "\n",
    "def corr_plt(df_plot, out_file, sig, title):\n",
    "    if (sig == 'SIG1') or (sig == 'SBS1'):\n",
    "        colorin = COLORS_SIGNATURES['SBS1']\n",
    "        markers=['o', 'x']\n",
    "    elif (sig == 'SIG5') or (sig == 'SBS5'):\n",
    "        colorin = COLORS_SIGNATURES['SBS5']\n",
    "        markers=['o', 'x']\n",
    "    elif (sig == 'healthy'):\n",
    "        colorin = \"#bdbdbd\"\n",
    "        sig = 'SBS5'\n",
    "        markers = [\"P\",'^']\n",
    "    else:\n",
    "        print(\"another signature! write SIG1 or SIG5\")\n",
    "    \n",
    "    # with scipy\n",
    "    coef_corr, pval_corr = stats.pearsonr(df_plot['AGE'], df_plot['MUTS_CLONAL_'+sig])\n",
    "\n",
    "    est = smf.ols(formula='MUTS_CLONAL_'+sig+' ~ AGE', data=df_plot).fit()\n",
    "    dfs = {}\n",
    "    fs = est.summary()\n",
    "    for item in fs.tables[0].data:\n",
    "        dfs[item[0].strip()] = item[1].strip()\n",
    "        dfs[item[2].strip()] = item[3].strip()\n",
    "    for item in fs.tables[2].data:\n",
    "        dfs[item[0].strip()] = item[1].strip()\n",
    "        dfs[item[2].strip()] = item[3].strip()\n",
    "    dfs = pd.Series(dfs)\n",
    "    coef_det = dfs['R-squared:']\n",
    "    intercept = round(est.params[0], 3)\n",
    "    slope = round(est.params[1], 3) # reg coefficient\n",
    "    print(est.summary())\n",
    "    \n",
    "    if len(df_plot['STAGE'].unique()) == 2:\n",
    "        fgrid = sns.lmplot(y='MUTS_CLONAL_'+sig, x='AGE', data=df_plot, hue='STAGE',size=3, aspect=2,legend=False, fit_reg=False,\n",
    "                      palette=[colorin],scatter_kws={'linewidths':1,'edgecolor':'k'}, markers=markers)\n",
    "    else:\n",
    "        fgrid = sns.lmplot(y='MUTS_CLONAL_'+sig, x='AGE', data=df_plot,size=3, aspect=2,legend=True, fit_reg=False,\n",
    "                      palette=colorin, scatter_kws={'linewidths':1,'edgecolor':'k','facecolors':colorin}, markers=['o'])\n",
    "    ax = fgrid.axes[0,0]\n",
    "    ax.set_xlim(0, 70)\n",
    "    ax.set_ylim(0, 2500)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    \n",
    "    handles.append(mpatches.Patch(color='none', label='r-Pearson:'+str(round(coef_corr, 2))+' p-value:'+'{:0.2e}'.format(pval_corr)+'\\n'+'R-squared:'+coef_det))\n",
    "    slope, intercept, r_value, p_value, slope_std_error = stats.linregress(df_plot['AGE'],df_plot['MUTS_CLONAL_'+sig])\n",
    "    handles.append(mpatches.Patch(color=colorin, label='$y=%3.7s*x+%3.7s$'%(slope, intercept)))\n",
    "    ax.legend(handles=handles,bbox_to_anchor=(1,0.5),prop={'size': 10})\n",
    "    \n",
    "    print('{:0.2e}'.format(pval_corr))\n",
    "\n",
    "    sns.regplot(x=\"AGE\", y=\"MUTS_CLONAL_\"+sig, data=df_plot, scatter=False, ax=ax,line_kws={\"color\": colorin})\n",
    "    \n",
    "    ax.set_ylabel(\"Clonal Mutations \\n of \"+sig[0:3]+\" \"+sig[-1])\n",
    "    ax.set_xlabel(\"Age\")\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(title)\n",
    "\n",
    "    fgrid.savefig(out_file, doi=200,bbox_inches = 'tight',pad_inches=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def corr_tall(df_plot, out_file, sig, title):\n",
    "    \n",
    "    markers={'TALL Adult':'o', 'TALL Adult (relapse)':'x','TALL Pediatric':'o', 'Multipotent progenitor cells (MPP)':'^', 'Hematopoietic stem cells (HSC)':\"P\"}\n",
    "    fgrid = sns.lmplot(y='MUTS_CLONAL_'+sig, x='AGE', data=df_plot, hue='SUBTYPE_LABEL',size=3, aspect=2,legend=False, fit_reg=False,\n",
    "                      palette={'TALL Adult':'#d50402', 'TALL Adult (relapse)':'#d50402', \n",
    "                               \"TALL Pediatric\":'#ff8080', 'Multipotent progenitor cells (MPP)':'#737373', \n",
    "                               'Hematopoietic stem cells (HSC)':'#737373'}, \n",
    "                           scatter_kws={'linewidths':1,'edgecolor':'k'}, markers=['o', 'x', 'o', \"P\",'^'])\n",
    "    \n",
    "    ax = fgrid.axes[0,0]\n",
    "    ax.set_xlim(0, 70)\n",
    "    \n",
    "    COLORS_SUBTYPES['Progenitor cells']='#737373'\n",
    "\n",
    "    sns.regplot(x=\"AGE\", y=\"MUTS_CLONAL_\"+sig, data=df_plot[df_plot['SUBTYPE PLOT'] == 'TALL Adult'], \n",
    "                scatter=False, ax=ax,line_kws={\"color\": COLORS_SUBTYPES['TALL Adult']})\n",
    "    sns.regplot(x=\"AGE\", y=\"MUTS_CLONAL_\"+sig, data=df_plot[df_plot['SUBTYPE PLOT'] == 'TALL Pediatric'], \n",
    "                scatter=False, ax=ax,line_kws={\"color\": COLORS_SUBTYPES['TALL Pediatric']})\n",
    "    sns.regplot(x=\"AGE\", y=\"MUTS_CLONAL_\"+sig, data=df_plot[df_plot['SUBTYPE PLOT'] == 'Progenitor cells'], \n",
    "                scatter=False, ax=ax,line_kws={\"color\":COLORS_SUBTYPES['Progenitor cells'] , 'linestyle':\"--\"})\n",
    "    \n",
    "    ax.set_ylabel(\"Clonal Mutations\\nof Signature \"+sig)\n",
    "    ax.set_xlabel(\"Age\")\n",
    "        \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    \n",
    "    for reg in df_plot['SUBTYPE PLOT'].unique():\n",
    "        dff = df_plot[df_plot['SUBTYPE PLOT'] == reg]\n",
    "        \n",
    "        coef_corr, pval_corr = stats.pearsonr(dff['AGE'], dff['MUTS_CLONAL_'+sig])\n",
    "        handles.append(mpatches.Patch(color=COLORS_SUBTYPES[reg], label='r-Pearson:'+str(round(coef_corr, 2))))\n",
    "        ax.legend(handles=handles,bbox_to_anchor=(1,0.5),prop={'size': 10})\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "    fgrid.savefig(out_file, doi=200,bbox_inches = 'tight',pad_inches=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def scatter(df, col_x, cols_y, filename):\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,1)\n",
    "    \n",
    "    ax = sns.scatterplot(x=col_x, y=cols_y, s= 100,\n",
    "                      hue=\"stage\", data=df)\n",
    "    \n",
    "    sns.regplot(x=col_x, y=cols_y, data=df, \n",
    "                scatter=False, ax=ax,line_kws={\"color\": \"#bdbdbd\"})\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    coef_corr = df[[col_x, cols_y]].corr('pearson')\n",
    "    coef_corr = coef_corr.loc[col_x, cols_y]\n",
    "    handles.append(mpatches.Patch(color='none', label='r-Pearson:'+str(round(coef_corr, 2))))\n",
    "    ax.legend(handles=handles,bbox_to_anchor=(1,0.5),prop={'size': 10})\n",
    "    \n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    fig.savefig(filename+\".svg\", dpi=300, bbox_inches='tight', format='svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clinical = pd.read_csv(\"../ext_files/all_cohort_clinical_groups.tsv\", sep='\\t')\n",
    "clinical = clinical[~clinical['COMPARISON'].isin(['AE6518_vs_AE6519', 'AE6521_vs_AE6522'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get only patients with known numerical age\n",
    "clinical = clinical[~clinical['AGE'].isnull()]\n",
    "clinical = clinical[~clinical['AGE'].isin(['Childhood SR', 'Childhood HR'])]\n",
    "clinical = clinical[~clinical['AGE'].str.contains(\"-\")]\n",
    "clinical['AGE'] = clinical['AGE'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_out = \"\" # path for the figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff_plot = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the results from fitting of signatures of deconstructSigs run. Here we expect the results from\n",
    "# all samples (primary and relapse) together. If you check ../ext_runs/run_deconstructSig/make_inputs_fitting_adults.ipynb\n",
    "# it should correspond to the results file signatures_weight.csv of a run with folder named run_subsets_together/\n",
    "dire_fitsig = \"\"\n",
    "df_adult = get_clonal_x_signature_patient(dire_fitsig, clinical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff_plot = df_adult.merge(clinical[['AGE', 'COMPARISON', 'PATIENT','STAGE', 'SUBTYPE_LABEL']], how='left', on=['PATIENT', 'STAGE'])\n",
    "dff_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff_plot = dff_plot.dropna() # in case there is no information\n",
    "dff_plot['SUBTYPE PLOT'] = 'TALL Adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_file = os.path.join(path_out, \"sig5_corr_age_adult_TALL_sarek.svg\")\n",
    "corr_plt(dff_plot[dff_plot['SUBTYPE PLOT'] == 'TALL Adult'], plot_file, 'SBS5', 'Adult TALL (in-house) cohort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CI intercept +/- {} {}\".format(str(round(649.215-397.3998, 3)), str(round(397.3998-145.585, 3))))\n",
    "print(\"CI slope +/- {} {}\".format(str(round(27.195-20.6128, 3)), str(round(20.6128-14.031, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_file =os.path.join(path_out, \"sig1_corr_age_adult_TALL_sarek.svg\")\n",
    "corr_plt(dff_plot[dff_plot['SUBTYPE PLOT'] == 'TALL Adult'], plot_file, 'SBS1', 'Adult TALL (in-house) cohort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CI intercept +/- {} {}\".format(str(round(343.738-172.1058, 3)), str(round(172.1058-0.473, 3))))\n",
    "print(\"CI slope +/- {} {}\".format(str(round(11.780-7.2936, 3)), str(round(7.2936-2.808, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add pediatric TALL dataframe Zhang et al., 2012; Nature Genetics\n",
    "\n",
    "dire_maf = \"\" # path to the folder of MAF files from Zhang et al., 2012; Nature Genetics\n",
    "\n",
    "# path to the folder with the run of deconstructSigs for primary samples of the cohort Zhang et al., 2012; Nature Genetics\n",
    "dire_fitsig = \"\"\n",
    "\n",
    "pry_pedia = get_clonal_x_signature_sample(os.path.join(dire_fitsig, 'TALL_Pediatric_pry'), dire_maf)\n",
    "pry_pedia.reset_index(inplace=True)\n",
    "pry_pedia.rename(columns={'index':'PATIENT'}, inplace=True)\n",
    "\n",
    "pry_pedia = pry_pedia.merge(clinical[['AGE', 'COMPARISON', 'PATIENT','STAGE', 'SUBTYPE_LABEL']], how='left', on='PATIENT')\n",
    "pry_pedia['SUBTYPE PLOT'] = 'TALL Pediatric'\n",
    "pry_pedia.dropna(subset=['AGE'], inplace=True)\n",
    "dff_plot = dff_plot.append(pry_pedia, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Add healthy tissue data from Osorio et al., 2018; Cell Reports publication \n",
    "\n",
    "# Dataframe with the signature weights from fitting signatures of data from Osorio et al., 2018; Cell Reports publication\n",
    "df_healthy = pd.read_csv(\"\", sep='\\t')\n",
    "\n",
    "# Dataframe of clinical data on each sample provided by the authors of Osorio et al., 2018; Cell Reports publication\n",
    "info_samples_healthy = pd.read_csv(\"\", sep='\\t')\n",
    "\n",
    "df_healthy['MUTS_CLONAL_SIG5'] = df_healthy['mutation_count']*df_healthy['SBS5']\n",
    "df_healthy = df_healthy.merge(info_samples_healthy[['Identifier', 'Age (years)', 'Cell type']], how='left', \n",
    "                              left_on='sample_id', right_on='Identifier')\n",
    "df_healthy.rename(columns={'Age (years)':'AGE', 'Cell type':'STAGE'}, inplace=True)\n",
    "df_healthy['STAGE'] = df_healthy['STAGE'].apply(lambda x: 'Hematopoietic stem cells (HSC)' if x=='HSC' else 'Multipotent progenitor cells (MPP)')\n",
    "\n",
    "dff_plot_TALL = dff_plot[['AGE', 'MUTS_CLONAL_SBS5', 'STAGE', 'SUBTYPE PLOT', 'SUBTYPE_LABEL']]\n",
    "df_healthy['SUBTYPE PLOT'] = 'Progenitor cells'\n",
    "df_healthy['SUBTYPE_LABEL'] = df_healthy['STAGE']\n",
    "df_healthy.sort_values('SUBTYPE_LABEL', inplace=True)\n",
    "df_healthy.rename(columns={'MUTS_CLONAL_SIG5':'MUTS_CLONAL_SBS5'}, inplace=True)\n",
    "df_plot = dff_plot_TALL.append(df_healthy[['AGE', 'MUTS_CLONAL_SBS5', 'STAGE', 'SUBTYPE PLOT', 'SUBTYPE_LABEL']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_plot.to_csv(\"../intermediate_files/data_points_figure4a.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_file = os.path.join(path_out, \"sig5_corr_age_TALL_join.svg\")\n",
    "corr_tall(df_plot, plot_file, 'SBS5', \"Age-related acumulation of mutations of TALL cohorts (Signature 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_file = os.path.join(path_out, \"sig5_healthy.svg\")\n",
    "corr_plt(df_healthy, plot_file, 'healthy','SBS5 from Hematopoietic Cells\\n(Osorio et al., 2018; Cell Reports)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CI intercept +/- {} {}\".format(str(round(67.885-22.3521, 3)), str(round(22.3521--23.181, 3))))\n",
    "print(\"CI slope +/- {} {}\".format(str(round(13.453-12.2119, 3)), str(round(12.2119-10.970, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check HSCP and SIG5 correlation\n",
    "\n",
    "HSCP profile looks similar to signature 5.\n",
    "\n",
    "We compared the fitting of signature 5 of our data with and without the HSCP signature recently described\n",
    "in  Osorio et al., 2018; Cell Reports publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First check ../ext_runs/run_deconstructSig/make_inputs_fitting_adults.ipynb. According to the intructions in \n",
    "# that notebook,the results run stored in old_weights_* dataframes should correspond to the ones in folder \n",
    "# run_samples/ whereas the dataframes hscp_weigths_* should be the weights of the folder run_samples_hemato/\n",
    "\n",
    "old_weigths_pry = pd.read_csv(\"\", sep='\\t')\n",
    "old_weigths_rel = pd.read_csv(\"\", sep='\\t')\n",
    "\n",
    "hscp_weigths_pry = pd.read_csv(\"\", sep='\\t')\n",
    "hscp_weigths_rel = pd.read_csv(\"\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_weigths_pry['stage'] = 'primary'\n",
    "old_weigths_rel['stage'] = 'relapse'\n",
    "\n",
    "hscp_weigths_pry['stage'] = 'primary'\n",
    "hscp_weigths_rel['stage'] = 'relapse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_old = old_weigths_pry.copy()\n",
    "weights_hscp = hscp_weigths_pry.copy()\n",
    "\n",
    "weights_old = weights_old.append(old_weigths_rel, ignore_index=True, sort=False)\n",
    "weights_hscp = weights_hscp.append(hscp_weigths_rel, ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_hscp.rename(columns={'SBS_hscp':'HSCP_signature'}, inplace=True)\n",
    "weights = weights_old.merge(weights_hscp, how='outer', on=['sample_id', 'stage'], suffixes=['_old', '_hscp'])\n",
    "weights['SBS5_hscp + HSCP_signature'] = weights['SBS5_hscp']+weights['HSCP_signature']\n",
    "weights['SBS5_old + unknown'] = weights['SBS5_old']+weights['unknown_hscp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter(weights, \"SBS5_old\", 'SBS5_hscp + HSCP_signature', os.path.join(path_out,\"contrib_sig5_old_vs_sig5_plus_sig_HSCP\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:filter_pipeline]",
   "language": "python",
   "name": "conda-env-filter_pipeline-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
